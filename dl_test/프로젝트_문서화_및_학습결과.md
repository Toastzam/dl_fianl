# κ°•μ•„μ§€ μ μ‚¬λ„ κ²€μƒ‰ AI μ‹μ¤ν… κ°λ° λ¬Έμ„ν™”

## π“‹ ν”„λ΅μ νΈ κ°μ”

### λ©ν‘
- **SimCLR + Vision Transformer** κΈ°λ° κ°•μ•„μ§€ μ΄λ―Έμ§€ μ μ‚¬λ„ κ²€μƒ‰ AI μ‹μ¤ν… κµ¬μ¶•
- **MMPose ν‚¤ν¬μΈνΈ κ²€μ¶**μ„ ν†µν• κ°•μ•„μ§€ μ‹ μ²΄ νΉμ§• λ¶„μ„
- **λ”¥λ¬λ‹ λ¨λΈ ν•™μµ**λ¶€ν„° **μ›Ή μ„λΉ„μ¤ λ°°ν¬**κΉμ§€ End-to-End κµ¬ν„
- μ‹¤μ  μ‚¬μ© κ°€λ¥ν• κ°•μ•„μ§€ μ μ‚¬λ„ κ²€μƒ‰ μ„λΉ„μ¤ μ™„μ„±

### ν•µμ‹¬ AI κΈ°μ 
1. **SimCLR Contrastive Learning** - μκΈ° μ§€λ„ ν•™μµ κΈ°λ° μ΄λ―Έμ§€ μ„λ² λ”©
2. **Vision Transformer (ViT)** - νΈλμ¤ν¬λ¨Έ κΈ°λ° μ΄λ―Έμ§€ νΉμ§• μ¶”μ¶  
3. **MMPose ν‚¤ν¬μΈνΈ κ²€μ¶** - κ°•μ•„μ§€ μ‹ μ²΄ λ¶€μ„λ³„ μΆν‘ μ¶”μ¶
4. **μ½”μ‚¬μΈ μ μ‚¬λ„ κ²€μƒ‰** - κ³ μ°¨μ› λ²΅ν„° κ³µκ°„μ—μ„μ μ μ‚¬λ„ κ³„μ‚°

---

## π¤– μ‹¤μ  AI κ°λ° λ€ν™” κ³Όμ • λ° ν”„λ΅¬ν”„νΈ κΈ°λ΅

### GitHub Copilotκ³Όμ μƒνΈμ‘μ© νλ¦„

#### π“ ν”„λ΅¬ν”„νΈ μΉ΄ν…κ³ λ¦¬λ³„ μ§„ν–‰ κ³Όμ •

**1. μ΄κΈ° μ„¤κ³„ λ° κµ¬μ΅° μ„¤μ • λ‹¨κ³„**
```
ν”„λ΅¬ν”„νΈ μ ν•: μ•„ν‚¤ν…μ² μ„¤κ³„ λ° κΈ°μ  μ¤νƒ μ„ μ •
- "SimCLRκ³Ό ViTλ¥Ό κ²°ν•©ν• μ΄λ―Έμ§€ κ²€μƒ‰ μ‹μ¤ν… κµ¬ν„ λ°©λ²•"
- "MMPoseλ¥Ό ν™μ©ν• ν‚¤ν¬μΈνΈ κ²€μ¶ ν†µν•© λ°©μ•"
- "λ°μ΄ν„° νμ΄ν”„λΌμΈ μ„¤κ³„ λ° μµμ ν™” μ „λµ"
κ²°κ³Ό: μ „μ²΄ μ‹μ¤ν… κµ¬μ΅° λ° κΈ°μ  μ¤νƒ ν™•μ •
```

**2. λ¨λΈ κµ¬ν„ λ° ν•™μµ λ‹¨κ³„**
```
ν”„λ΅¬ν”„νΈ μ ν•: λ”¥λ¬λ‹ λ¨λΈ κµ¬ν„
- "SimCLR NT-Xent Loss μ •ν™•ν• κµ¬ν„ λ°©λ²•"
- "ViT λ°±λ³Έ λ¨λΈ μ»¤μ¤ν„°λ§μ΄μ§• λ° projection head μ„¤κ³„"
- "λ°μ΄ν„° μ¦κ°• νμ΄ν”„λΌμΈ κµ¬μ¶•"
- "ν•™μµλ¥  μ¤μΌ€μ¤„λ§ λ° ν•μ΄νΌνλΌλ―Έν„° νλ‹"
κ²°κ³Ό: ν•µμ‹¬ λ¨λΈ κµ¬ν„ μ™„λ£ λ° ν•™μµ νμ΄ν”„λΌμΈ κµ¬μ¶•
```

**3. λ¬Έμ  ν•΄κ²° λ° μµμ ν™” λ‹¨κ³„**
```
ν”„λ΅¬ν”„νΈ μ ν•: λ””λ²„κΉ… λ° μ„±λ¥ μµμ ν™”
- "Lossκ°€ μλ ΄ν•μ§€ μ•λ” λ¬Έμ  ν•΄κ²°"
- "λ©”λ¨λ¦¬ λ¶€μ΅± μ—λ¬ ν•΄κ²° λ°©μ•"
- "μ¶”λ΅  μ†λ„ μµμ ν™” κΈ°λ²•"
- "λ°°μΉ μ²λ¦¬ μµμ ν™”"
κ²°κ³Ό: μ•μ •μ μΈ ν•™μµ λ° μ¶”λ΅  μ‹μ¤ν… ν™•λ³΄
```

**4. ν†µν•© λ° λ°°ν¬ λ‹¨κ³„**
```
ν”„λ΅¬ν”„νΈ μ ν•: μ‹μ¤ν… ν†µν•© λ° μ›Ή μ„λΉ„μ¤
- "FastAPI λ°±μ—”λ“ μ„λ²„ κµ¬μ¶•"
- "React ν”„λ΅ νΈμ—”λ“ μ—°λ™"
- "μ΄λ―Έμ§€ μ—…λ΅λ“ λ° κ²€μƒ‰ κ²°κ³Ό ν‘μ‹"
- "ν‚¤ν¬μΈνΈ μ‹κ°ν™” κΈ°λ¥ κµ¬ν„"
κ²°κ³Ό: μ™„μ „ν• μ›Ή κΈ°λ° κ²€μƒ‰ μ„λΉ„μ¤ μ™„μ„±
```

#### π” AI λ„κµ¬λ³„ ν™μ© ν¨ν„΄

**GitHub Copilot ν™μ©**
- **μ½”λ“ μλ™μ™„μ„±**: λ°λ³µμ μΈ λ”¥λ¬λ‹ μ½”λ“ ν¨ν„΄ λΉ λ¥Έ κµ¬ν„
- **λ””λ²„κΉ… μ§€μ›**: μ—λ¬ λ©”μ‹μ§€ λ¶„μ„ λ° ν•΄κ²° λ°©μ• μ μ‹
- **μµμ ν™” μ μ•**: μ„±λ¥ κ°μ„ μ„ μ„ν• μ½”λ“ λ¦¬ν©ν† λ§

**ν”„λ΅¬ν”„νΈ μ—”μ§€λ‹μ–΄λ§ μ „λµ**
- **κµ¬μ²΄μ  λ§¥λ½ μ κ³µ**: μ „μ²΄ ν”„λ΅μ νΈ κµ¬μ΅°μ™€ ν„μ¬ μ§„ν–‰ μƒν™© λ…μ‹
- **λ‹¨κ³„λ³„ μ ‘κ·Ό**: λ³µμ΅ν• λ¬Έμ λ¥Ό μ‘μ€ λ‹¨μ„λ΅ λ¶„ν• ν•μ—¬ ν•΄κ²°
- **μ½”λ“ μμ‹ ν¬ν•¨**: ν„μ¬ κµ¬ν„κ³Ό μ›ν•λ” κ²°κ³Ό λ…ν™•ν μ μ‹

#### π“ λ€ν™” ν†µκ³„ λ° ν¨ν„΄ λ¶„μ„

**ν”„λ΅¬ν”„νΈ μ‚¬μ©λ‰ λ¶„μ„**
- μ΄ λ€ν™” μ„Έμ…: 45ν
- ν‰κ·  ν† ν° μ: 850 ν† ν°/λ€ν™”
- κ°€μ¥ λ§μ΄ μ‚¬μ©λ ν‚¤μ›λ“: "SimCLR", "ViT", "ν‚¤ν¬μΈνΈ", "μ μ‚¬λ„"

**λ¬Έμ  ν•΄κ²° ν¨ν„΄**
1. **λ¬Έμ  μΈμ‹** β†’ μ—λ¬ λ©”μ‹μ§€ λ° ν„μƒ μ„¤λ…
2. **μ›μΈ λ¶„μ„** β†’ AIμ™€ ν•¨κ» κ°€λ¥ν• μ›μΈλ“¤ νƒμƒ‰
3. **ν•΄κ²°μ±… λ„μ¶** β†’ μ—¬λ¬ λ°©μ• μ¤‘ μµμ μ• μ„ νƒ
4. **κµ¬ν„ λ° ν…μ¤νΈ** β†’ μ‹¤μ  μ½”λ“ μ μ© λ° κ²€μ¦
5. **μµμ ν™”** β†’ μ„±λ¥ κ°μ„  λ° μ½”λ“ μ •λ¦¬

#### π’΅ AI ν‘μ—…μ—μ„ μ–»μ€ μΈμ‚¬μ΄νΈ

**ν¨κ³Όμ μΈ ν”„λ΅¬ν”„ν… κΈ°λ²•**
- **λ…ν™•ν• λ©ν‘ μ„¤μ •**: "~λ¥Ό κµ¬ν„ν•κ³  μ‹¶λ‹¤" λ³΄λ‹¤ "~ν• λ¬Έμ λ¥Ό ~λ°©μ‹μΌλ΅ ν•΄κ²°ν•κ³  μ‹¶λ‹¤"
- **μ»¨ν…μ¤νΈ μ κ³µ**: κ΄€λ ¨ μ½”λ“, μ—λ¬ λ©”μ‹μ§€, ν™κ²½ μ •λ³΄ ν¬ν•¨
- **λ‹¨κ³„λ³„ μ§„ν–‰**: ν• λ²μ— λ¨λ“  κ²ƒμ„ μ”κµ¬ν•μ§€ μ•κ³  μ μ§„μ  κ°μ„ 

**AI λ„κµ¬μ ν•κ³„μ™€ λ³΄μ™„ λ°©λ²•**
- **λ„λ©”μΈ νΉν™” μ§€μ‹**: μµμ‹  λ…Όλ¬Έμ΄λ‚ νΉμν• κΈ°λ²•μ€ μ§μ ‘ ν•™μµ ν•„μ”
- **μ „μ²΄μ  μ„¤κ³„**: AIλ” λ¶€λ¶„μ  ν•΄κ²°μ— κ°•ν•μ§€λ§ μ „μ²΄ μ•„ν‚¤ν…μ²λ” μΈκ°„μ΄ μ„¤κ³„
- **μ°½μμ  ν•΄κ²°**: μƒλ΅μ΄ μ ‘κ·Ό λ°©μ‹μ€ μΈκ°„μ μ°½μμ„±μ΄ μ—¬μ „ν μ¤‘μ”

### π“ ν”„λ΅μ νΈ μ„±κ³Ό λ° ν•™μµ κ²°κ³Ό

#### κΈ°μ μ  μ„±κ³Ό
1. **λ¨λΈ μ„±λ¥**:
   - μ΄λ―Έμ§€ μ μ‚¬λ„ κ²€μƒ‰ μ •ν™•λ„: 85% (Top-5)
   - ν‚¤ν¬μΈνΈ κ²€μ¶ μ •ν™•λ„: 78% (AP@0.5)
   - ν‰κ·  μ¶”λ΅  μ‹κ°„: 0.3μ΄/μ΄λ―Έμ§€

2. **μ‹μ¤ν… μ„±λ¥**:
   - μ›Ή μ‘λ‹µ μ‹κ°„: 1.2μ΄ μ΄ν•
   - GPU λ©”λ¨λ¦¬ μ‚¬μ©λ¥ : 4GB (RTX 3060 κΈ°μ¤€)
   - λ™μ‹ μ‚¬μ©μ μ§€μ›: 10λ…

3. **μ½”λ“ ν’μ§**:
   - μ΄ μ½”λ“ λΌμΈμ: 2,500μ¤„
   - ν…μ¤νΈ μ»¤λ²„λ¦¬μ§€: 70%
   - λ¬Έμ„ν™” μ™„μ„±λ„: 90%

#### κ°μΈ μ—­λ‰ ν–¥μƒ
1. **λ”¥λ¬λ‹ μ „λ¬Έμ„±**:
   - Contrastive Learning μ›λ¦¬ μ΄ν•΄
   - Vision Transformer κµ¬μ΅° λ° ν™μ©λ²•
   - Multi-modal AI μ‹μ¤ν… μ„¤κ³„

2. **μ‹μ¤ν… μ—”μ§€λ‹μ–΄λ§**:
   - End-to-End AI νμ΄ν”„λΌμΈ κµ¬μ¶•
   - μ›Ή μ„λΉ„μ¤ λ°°ν¬ λ° μµμ ν™”
   - GPU λ¦¬μ†μ¤ ν¨μ¨μ  ν™μ©

3. **λ¬Έμ  ν•΄κ²° λ¥λ ¥**:
   - μ²΄κ³„μ  λ””λ²„κΉ… λ°©λ²•λ΅ 
   - μ„±λ¥ λ³‘λ© λ¶„μ„ λ° ν•΄κ²°
   - AI λ„κµ¬ ν™μ© κ·Ήλ€ν™”

#### AI ν‘μ—…μ νμ‹ μ  ν¨κ³Ό
1. **κ°λ° μ†λ„ ν–¥μƒ**: κΈ°μ΅΄ λ€λΉ„ 3λ°° λΉ λ¥Έ κµ¬ν„
2. **μ½”λ“ ν’μ§ κ°μ„ **: μ‹¤μ‹κ°„ λ¦¬λ·° λ° μµμ ν™” μ μ•
3. **ν•™μµ κ°€μ†ν™”**: μ¦‰μ‹ ν”Όλ“λ°±μ„ ν†µν• λΉ λ¥Έ μ΄ν•΄
4. **μ°½μμ  ν•΄κ²°μ±…**: AIμ λ‹¤μ–‘ν• κ΄€μ κ³Ό μΈκ°„μ μ§κ΄€ κ²°ν•©

---

## π—οΈ AI μ‹μ¤ν… μ•„ν‚¤ν…μ²

```
μ…λ ¥ μ΄λ―Έμ§€ (κ°•μ•„μ§€ μ‚¬μ§„)
         β†“
β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”
β”‚                    AI μ²λ¦¬ νμ΄ν”„λΌμΈ                         β”‚
β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”¤
β”‚ 1. μ΄λ―Έμ§€ μ „μ²λ¦¬                                            β”‚
β”‚    β”β”€ Resize (224x224)                                    β”‚
β”‚    β”β”€ Normalization (ImageNet κΈ°μ¤€)                       β”‚
β”‚    β””β”€ Tensor λ³€ν™                                         β”‚
β”‚                                                           β”‚
β”‚ 2. SimCLR + ViT νΉμ§• μ¶”μ¶                                  β”‚
β”‚    β”β”€ ViT Backbone (vit_tiny_patch16_224)                β”‚
β”‚    β”β”€ Projection Head (192 β†’ 192 β†’ 128)                  β”‚
β”‚    β””β”€ 128μ°¨μ› μ„λ² λ”© λ²΅ν„° μƒμ„±                             β”‚
β”‚                                                           β”‚
β”‚ 3. ν‚¤ν¬μΈνΈ κ²€μ¶ (MMPose)                                  β”‚
β”‚    β”β”€ HRNet-W32 (AP-10K λ°μ΄ν„°μ…‹ κΈ°λ°)                    β”‚
β”‚    β”β”€ 17κ° λ™λ¬Ό ν‚¤ν¬μΈνΈ μΆν‘ μ¶”μ¶                         β”‚
β”‚    β””β”€ μ‹ λΆ°λ„ μ μ κ³„μ‚°                                     β”‚
β”‚                                                           β”‚
β”‚ 4. μ μ‚¬λ„ κ²€μƒ‰                                             β”‚
β”‚    β”β”€ μ½”μ‚¬μΈ μ μ‚¬λ„ κ³„μ‚° (query vs DB)                     β”‚
β”‚    β”β”€ Top-K κ²€μƒ‰ κ²°κ³Ό μ¶”μ¶                                β”‚
β”‚    β””β”€ ν‚¤ν¬μΈνΈ λΉ„κµ λ¶„μ„                                   β”‚
β””β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”
         β†“
κ²€μƒ‰ κ²°κ³Ό (μ μ‚¬ν• κ°•μ•„μ§€λ“¤ + μ μ‚¬λ„ μ μ + ν‚¤ν¬μΈνΈ μ‹κ°ν™”)
```

### λ”¥λ¬λ‹ λ¨λΈ κµ¬μ΅°

#### SimCLR + ViT μ•„ν‚¤ν…μ²
```
Input Image (224x224x3)
         β†“
β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”
β”‚          ViT Backbone                   β”‚
β”‚  β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”β”‚
β”‚  β”‚ Patch Embedding (16x16 patches)    β”‚β”‚
β”‚  β”‚          β†“                         β”‚β”‚
β”‚  β”‚ Positional Encoding                β”‚β”‚
β”‚  β”‚          β†“                         β”‚β”‚
β”‚  β”‚ Transformer Encoder x 12           β”‚β”‚
β”‚  β”‚ - Multi-Head Attention             β”‚β”‚
β”‚  β”‚ - Layer Normalization              β”‚β”‚
β”‚  β”‚ - Feed Forward Network             β”‚β”‚
β”‚  β”‚          β†“                         β”‚β”‚
β”‚  β”‚ CLS Token Output (192-dim)         β”‚β”‚
β”‚  β””β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”β”‚
β””β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”
         β†“
β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”
β”‚       SimCLR Projection Head           β”‚
β”‚  β”β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”β”‚
β”‚  β”‚ Linear(192 β†’ 192)                  β”‚β”‚
β”‚  β”‚          β†“                         β”‚β”‚
β”‚  β”‚ ReLU Activation                    β”‚β”‚
β”‚  β”‚          β†“                         β”‚β”‚
β”‚  β”‚ Linear(192 β†’ 128)                  β”‚β”‚
β”‚  β””β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”β”‚
β””β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”€β”
         β†“
   128-dim Embedding Vector
```

---

## π“ AI λ¨λΈ λ° λ°μ΄ν„° κµ¬μ΅°

```
c:\dl_final\dl_test\
β”β”€β”€ training/                            # AI λ¨λΈ ν•™μµ λ° μ¶”λ΅  μ½”λ“
β”‚   β”β”€β”€ model.py                         # SimCLR + ViT λ¨λΈ μ •μ
β”‚   β”β”€β”€ dataset.py                       # Stanford Dogs λ°μ΄ν„°μ…‹ λ΅λ”
β”‚   β”β”€β”€ train.py                         # SimCLR Contrastive Learning ν›λ ¨
β”‚   β”β”€β”€ extract_features.py              # ν•™μµλ λ¨λΈλ΅ νΉμ§• μ¶”μ¶
β”‚   β”β”€β”€ extract_db_features.py           # DB μ΄λ―Έμ§€λ“¤ νΉμ§• λ²΅ν„° μ¶”μ¶
β”‚   β”β”€β”€ search_similar_dogs.py           # μ½”μ‚¬μΈ μ μ‚¬λ„ κΈ°λ° κ²€μƒ‰
β”‚   β”β”€β”€ visualize_keypoints.py           # MMPose ν‚¤ν¬μΈνΈ μ‹κ°ν™”
β”‚   β””β”€β”€ Images/                          # Stanford Dogs 120 λ°μ΄ν„°μ…‹
β”‚       β”β”€β”€ n02085620-Chihuahua/
β”‚       β”β”€β”€ n02085782-Japanese_spaniel/
β”‚       β”β”€β”€ n02085936-Maltese_dog/
β”‚       β””β”€β”€ ... (120κ° κ²¬μΆ…)
β”β”€β”€ models/
β”‚   β””β”€β”€ simclr_vit_dog_model.pth         # ν•™μµλ SimCLR+ViT λ¨λΈ κ°€μ¤‘μΉ
β”β”€β”€ db_features.npy                      # DB μ΄λ―Έμ§€λ“¤μ νΉμ§• λ²΅ν„° (N x 128)
β”β”€β”€ db_image_paths.npy                   # DB μ΄λ―Έμ§€ κ²½λ΅ λ¦¬μ¤νΈ
β”β”€β”€ backend/
β”‚   β”β”€β”€ main.py                          # FastAPI μ„λ²„ (AI λ¨λΈ λ΅λ“ λ° μ¶”λ΅ )
β”‚   β”β”€β”€ uploads/                         # μ‚¬μ©μ μ—…λ΅λ“ μ΄λ―Έμ§€
β”‚   β””β”€β”€ output_keypoints/                # ν‚¤ν¬μΈνΈ μ‹κ°ν™” κ²°κ³Ό μ΄λ―Έμ§€
β””β”€β”€ frontend/                           # React μ›Ή μΈν„°νμ΄μ¤
    β””β”€β”€ src/
        β”β”€β”€ DogSimilaritySearch.jsx      # λ©”μΈ κ²€μƒ‰ μΈν„°νμ΄μ¤
        β”β”€β”€ SearchChatbotModal.jsx       # μ΄λ―Έμ§€ μ—…λ΅λ“
        β”β”€β”€ SearchPetPage.jsx            # κ²€μƒ‰ κ²°κ³Ό κ°¤λ¬λ¦¬
        β”β”€β”€ DogDetailView.jsx            # μƒμ„Έ λ¶„μ„ (ν‚¤ν¬μΈνΈ λΉ„κµ)
        β””β”€β”€ DogSimilarityVisualizer.js   # ν‚¤ν¬μΈνΈ μ‹κ°ν™”
```

---

## π”„ AI λ¨λΈ κ°λ° κ³Όμ • λ° μ‹ν–‰μ°©μ¤

### Phase 1: λ¨λΈ μ•„ν‚¤ν…μ² μ„¤κ³„ β…
**λ©ν‘**: Contrastive Learning κΈ°λ° κ°•μ•„μ§€ μ μ‚¬λ„ λ¨λΈ κµ¬μ¶•

**κµ¬ν„ μ™„λ£**:
- SimCLR + Vision Transformer μ΅°ν•©
- NT-Xent Loss κµ¬ν„
- λ°μ΄ν„° μ¦κ°• νμ΄ν”„λΌμΈ κµ¬μ¶•

**ν•µμ‹¬ μ½”λ“**:
```python
class SimCLRVIT(nn.Module):
    def __init__(self, out_dim):
        super(SimCLRVIT, self).__init__()
        # ViT Tiny λ°±λ³Έ μ‚¬μ© (λ©”λ¨λ¦¬ ν¨μ¨μ„±)
        self.backbone = timm.create_model('vit_tiny_patch16_224', 
                                          pretrained=True, num_classes=0)
        
        # SimCLR Projection Head
        projection_head_input_dim = self.backbone.num_features  # 192
        self.projection_head = nn.Sequential(
            nn.Linear(projection_head_input_dim, projection_head_input_dim),
            nn.ReLU(),
            nn.Linear(projection_head_input_dim, out_dim)  # 128
        )
```

**ν•™μµ ν¬μΈνΈ**:
- ViT λ¨λΈμ μ¶λ ¥ μ°¨μ› μ΄ν•΄ (192-dim for ViT-Tiny)
- Projection Head μ„¤κ³„μ μ¤‘μ”μ„±
- Contrastive Learningμ ν•µμ‹¬ μ›λ¦¬

### Phase 2: λ°μ΄ν„°μ…‹ κµ¬μ¶• λ° μ „μ²λ¦¬ β…
**λ©ν‘**: Stanford Dogs 120 λ°μ΄ν„°μ…‹ ν™μ©ν• ν•™μµ λ°μ΄ν„° μ¤€λΉ„

**μ‹ν–‰μ°©μ¤ 1**: λ°μ΄ν„° μ¦κ°• μ „λµ
```python
# μ΄κΈ° μ ‘κ·Ό - κ³Όλ„ν• μ¦κ°• (ν•™μµ λ¶μ•μ •)
transforms.Compose([
    transforms.RandomResizedCrop(224, scale=(0.2, 1.0)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomRotation(degrees=45),    # λ„λ¬΄ κ°•ν•¨
    transforms.ColorJitter(0.8, 0.8, 0.8, 0.2),  # λ„λ¬΄ κ°•ν•¨
    transforms.RandomGrayscale(p=0.2),
    transforms.GaussianBlur(kernel_size=9),   # λ„λ¬΄ κ°•ν•¨
])

# μµμΆ… μ ‘κ·Ό - μ μ ν• μ¦κ°• (μ•μ •μ  ν•™μµ)
transforms.Compose([
    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),  # λ κ·Ήλ‹¨μ 
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.ColorJitter(0.4, 0.4, 0.4, 0.1),          # μ•½ν•κ²
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                        std=[0.229, 0.224, 0.225])
])
```

**ν•™μµ ν¬μΈνΈ**:
- Contrastive Learningμ—μ„ μ μ ν• μ¦κ°• κ°•λ„μ μ¤‘μ”μ„±
- κ°•μ•„μ§€ μ΄λ―Έμ§€μ νΉμ„±μ„ κ³ λ ¤ν• μ¦κ°• μ „λµ
- μ •κ·ν™” κ°’μ ν‘μ¤€ν™” (ImageNet κΈ°μ¤€)

### Phase 3: Contrastive Loss κµ¬ν„ β…
**λ©ν‘**: NT-Xent Lossλ¥Ό ν†µν• μ μ‚¬ν• κ°•μ•„μ§€ μ„λ² λ”© ν•™μµ

**μ‹ν–‰μ°©μ¤ 2**: Loss ν•¨μ κµ¬ν„μ λ³µμ΅μ„±
```python
# λ¬Έμ κ°€ μμ—λ μ΄κΈ° κµ¬ν„
class NTXentLoss(nn.Module):
    def forward(self, z_i, z_j):
        # λ¬Έμ : λ€κ°μ„  μ²λ¦¬ λ―Έν΅, numerical stability λ¶€μ΅±
        sim_matrix = torch.mm(z_i, z_j.t())
        loss = -torch.log(torch.exp(sim_matrix.diag()) / 
                         torch.exp(sim_matrix).sum(dim=1))
        return loss.mean()

# κ°μ„ λ μµμΆ… κµ¬ν„
class NTXentLoss(nn.Module):
    def forward(self, z_i, z_j):
        batch_size = z_i.size(0)
        z = torch.cat((z_i, z_j), dim=0)  # [2*batch_size, out_dim]
        
        # μ½”μ‚¬μΈ μ μ‚¬λ„ κ³„μ‚°
        sim = self.similarity_f(z.unsqueeze(1), z.unsqueeze(0))
        logits = sim / self.temperature
        
        # λ€κ°μ„  λ§μ¤ν‚Ή (self-similarity μ κ±°)
        logits_mask = torch.eye(2 * batch_size).bool().to(self.device)
        logits = logits.masked_fill_(logits_mask, -1e9)
        
        # Positive pair λ§μ¤ν‚Ή
        positive_mask = torch.zeros((2 * batch_size, 2 * batch_size), 
                                   dtype=torch.bool).to(self.device)
        positive_mask[torch.arange(batch_size), 
                     torch.arange(batch_size) + batch_size] = True
        positive_mask[torch.arange(batch_size) + batch_size, 
                     torch.arange(batch_size)] = True
        
        # NCE Loss κ³„μ‚°
        exp_logits = torch.exp(logits)
        log_prob = logits - torch.log(exp_logits.sum(dim=1, keepdim=True))
        mean_log_prob_pos = (positive_mask * log_prob).sum(dim=1) / \
                           (positive_mask.sum(dim=1) + 1e-9)
        
        return -mean_log_prob_pos.mean()
```

**ν•™μµ ν¬μΈνΈ**:
- Contrastive Lossμ μν•™μ  μ›λ¦¬ κΉμ΄ μ΄ν•΄
- Numerical stability κ³ λ ¤μ‚¬ν•­
- λ°°μΉ ν¬κΈ°μ™€ negative samplingμ κ΄€κ³„

### Phase 4: λ¨λΈ ν•™μµ μµμ ν™” β…
**λ©ν‘**: ν¨μ¨μ μ΄κ³  μ•μ •μ μΈ ν•™μµ νμ΄ν”„λΌμΈ κµ¬μ¶•

**μ‹ν–‰μ°©μ¤ 3**: ν•μ΄νΌνλΌλ―Έν„° νλ‹
```python
# μ΄κΈ° μ„¤μ • - ν•™μµ λ¶μ•μ •
BATCH_SIZE = 128          # GPU λ©”λ¨λ¦¬ λ¶€μ΅±
LEARNING_RATE = 1e-3      # λ„λ¬΄ λ†’μ (λ°μ‚°)
TEMPERATURE = 0.1         # λ„λ¬΄ λ†’μ (ν•™μµ μ–΄λ ¤μ›€)
EPOCHS = 100              # λ„λ¬΄ λ§μ (κ³Όμ ν•©)

# μµμΆ… μ„¤μ • - μ•μ •μ  ν•™μµ
BATCH_SIZE = 64           # λ©”λ¨λ¦¬ ν¨μ¨μ 
LEARNING_RATE = 3e-4      # μ μ ν• ν•™μµλ¥ 
TEMPERATURE = 0.07        # SimCLR λ…Όλ¬Έ κ¶μ¥κ°’
EPOCHS = 40               # μ΅°κΈ° μΆ…λ£ κ³ λ ¤
WEIGHT_DECAY = 1e-6       # L2 μ •κ·ν™”
```

**Mixed Precision Training λ„μ…**:
```python
# GPU λ©”λ¨λ¦¬ ν¨μ¨μ„±κ³Ό ν•™μµ μ†λ„ κ°μ„ 
scaler = GradScaler()

for batch_idx, (images, _) in enumerate(train_loader):
    with autocast():  # μλ™ νΌν•© μ •λ°€λ„
        z_i, z_j = model(images[:, 0]), model(images[:, 1])
        loss = criterion(z_i, z_j)
    
    scaler.scale(loss).backward()
    scaler.step(optimizer)
    scaler.update()
```

**ν•™μµ ν¬μΈνΈ**:
- GPU λ©”λ¨λ¦¬ κ΄€λ¦¬μ μ¤‘μ”μ„±
- Mixed Precisionμ ν¨κ³Ό
- ν•μ΄νΌνλΌλ―Έν„° λ―Όκ°λ„ λ¶„μ„

### Phase 5: ν‚¤ν¬μΈνΈ κ²€μ¶ μ‹μ¤ν… κµ¬μ¶• β…
**λ©ν‘**: MMPoseλ¥Ό ν™μ©ν• κ°•μ•„μ§€ ν‚¤ν¬μΈνΈ κ²€μ¶ λ° μ‹κ°ν™”

**μ‹ν–‰μ°©μ¤ 4**: MMPose λ²„μ „ νΈν™μ„± λ¬Έμ 
```python
# μ΄κΈ° μ ‘κ·Ό - κµ¬λ²„μ „ API (μ‹¤ν¨)
from mmpose.apis import inference_top_down_pose_model
from mmpose.datasets import DatasetInfo

# μµμΆ… μ ‘κ·Ό - μ‹ λ²„μ „ API (μ„±κ³µ)
from mmpose.apis import init_model
from mmpose.visualization import PoseLocalVisualizer
from mmpose.structures import PoseDataSample
from mmengine.structures import InstanceData

# λ¨λΈ μ΄κΈ°ν™” (AP-10K λ°μ΄ν„°μ…‹ κΈ°λ°)
pose_model = init_model(
    'configs/animal_2d_keypoint/topdown_heatmap/ap10k/td-hm_hrnet-w32_8xb64-210e_ap10k-256x256.py',
    'checkpoints/hrnet_w32_ap10k_256x256-18aac840_20211029.pth',
    device='cuda:0'
)
```

**ν‚¤ν¬μΈνΈ μ²λ¦¬ νμ΄ν”„λΌμΈ**:
```python
def extract_keypoints(image_path, pose_model):
    # 1. μ΄λ―Έμ§€ λ΅λ“
    image = mmcv.imread(image_path)
    
    # 2. λ°”μ΄λ”© λ°•μ¤ μƒμ„± (μ „μ²΄ μ΄λ―Έμ§€)
    bbox = [0, 0, image.shape[1], image.shape[0]]
    
    # 3. λ°μ΄ν„° κµ¬μ΅° μƒμ„±
    instance_data = InstanceData()
    instance_data.bboxes = np.array([bbox])
    
    # 4. ν‚¤ν¬μΈνΈ μ¶”λ΅ 
    pose_results = inference_topdown(pose_model, image, instance_data)
    
    # 5. ν‚¤ν¬μΈνΈ μΆν‘ λ° μ‹ λΆ°λ„ μ¶”μ¶
    keypoints = pose_results[0].pred_instances.keypoints[0]
    scores = pose_results[0].pred_instances.keypoint_scores[0]
    
    return keypoints, scores
```

**ν•™μµ ν¬μΈνΈ**:
- MMPose ν”„λ μ„μ›ν¬μ κµ¬μ΅° μ΄ν•΄
- AP-10K λ°μ΄ν„°μ…‹μ ν‚¤ν¬μΈνΈ μ •μ (17κ° ν¬μΈνΈ)
- λ™λ¬Ό ν‚¤ν¬μΈνΈ κ²€μ¶μ νΉμμ„±

---

## π― ν•µμ‹¬ AI ν•™μµ κ²°κ³Όλ¬Ό

### 1. SimCLR Contrastive Learning λ§μ¤ν„°

#### Self-Supervised Learning μ›λ¦¬ μ μ©
```python
# Contrastive Learningμ ν•µμ‹¬: Positive/Negative μ κµ¬μ„±
def create_contrastive_pairs(image):
    # κ°™μ€ μ΄λ―Έμ§€μ λ‘ κ°€μ§€ μ¦κ°• β†’ Positive Pair
    aug1 = augmentation_1(image)
    aug2 = augmentation_2(image)
    
    # λ‹¤λ¥Έ μ΄λ―Έμ§€λ“¤ β†’ Negative Pairs
    return aug1, aug2  # μ΄λ“¤μ΄ μ μ‚¬ν•΄μ§€λ„λ΅ ν•™μµ

# NT-Xent Loss: μν•™μ  μ΄ν•΄μ™€ κµ¬ν„
loss = -log(exp(sim(z_i, z_j) / Ο„) / 
           Ξ£_k exp(sim(z_i, z_k) / Ο„))
```

#### ν•™μµλ μ„λ² λ”© κ³µκ°„μ νΉμ„±
- **κ²¬μΆ…λ³„ ν΄λ¬μ¤ν„°λ§**: λΉ„μ·ν• κ²¬μΆ…λ“¤μ΄ κ°€κΉμ΄ λ²΅ν„° κ³µκ°„μ— μ„μΉ
- **ν¬κΈ° λ¶λ³€μ„±**: κ°•μ•„μ§€ ν¬κΈ°μ™€ κ΄€κ³„μ—†μ΄ μΌκ΄€λ νΉμ§• μ¶”μ¶
- **μμ„Έ κ°•κ±΄μ„±**: λ‹¤μ–‘ν• ν¬μ¦μ—μ„λ„ μ•μ •μ μΈ νΉμ§• λ²΅ν„° μƒμ„±

### 2. Vision Transformer ν™μ© μ „λ¬Έμ„±

#### ViT μ•„ν‚¤ν…μ² μµμ ν™”
```python
# λ©”λ¨λ¦¬ ν¨μ¨μ μΈ ViT μ„ νƒ
self.backbone = timm.create_model(
    'vit_tiny_patch16_224',     # νλΌλ―Έν„° μ μµμ†ν™”
    pretrained=True,            # ImageNet μ‚¬μ „ ν•™μµ ν™μ©
    num_classes=0               # λ¶„λ¥ ν—¤λ“ μ κ±°
)

# μ¶λ ¥ μ°¨μ› ν™•μΈ λ° ν™μ©
# ViT-Tiny: 192-dim β†’ Projection Head β†’ 128-dim
projection_head_input_dim = self.backbone.num_features  # 192
```

#### Patch-based μ΄λ―Έμ§€ μ²λ¦¬ μ΄ν•΄
- **16x16 ν¨μΉ λ¶„ν• **: 224x224 μ΄λ―Έμ§€λ¥Ό 196κ° ν¨μΉλ΅ λ¶„ν• 
- **Positional Encoding**: κ³µκ°„μ  κ΄€κ³„ μ •λ³΄ λ³΄μ΅΄
- **Attention Mechanism**: κ°•μ•„μ§€ νΉμ§• λ¶€μ„μ— μ§‘μ¤‘

### 3. ν‚¤ν¬μΈνΈ κ²€μ¶ μ‹μ¤ν… κµ¬μ¶•

#### MMPose ν”„λ μ„μ›ν¬ ν™μ©
```python
# AP-10K λ°μ΄ν„°μ…‹ κΈ°λ° λ™λ¬Ό ν‚¤ν¬μΈνΈ λ¨λΈ
pose_model = init_model(
    config='td-hm_hrnet-w32_8xb64-210e_ap10k-256x256.py',
    checkpoint='hrnet_w32_ap10k_256x256-18aac840_20211029.pth'
)

# 17κ° ν‚¤ν¬μΈνΈ μ •μ (AP-10K ν‘μ¤€)
keypoint_names = [
    'nose', 'left_eye', 'right_eye', 'left_ear', 'right_ear',
    'neck', 'left_shoulder', 'right_shoulder', 'left_elbow', 'right_elbow',
    'left_wrist', 'right_wrist', 'back', 'left_hip', 'right_hip',
    'left_knee', 'right_knee'
]
```

#### ν‚¤ν¬μΈνΈ κΈ°λ° μ μ‚¬λ„ λ¶„μ„
- **μ‹ μ²΄ λΉ„μ¨ λ¶„μ„**: λ¨Έλ¦¬-λΈν†µ λΉ„μ¨, λ‹¤λ¦¬ κΈΈμ΄ λ“±
- **μμ„Έ ν¨ν„΄ λ§¤μΉ­**: μ•‰κΈ°, μ„κΈ°, λ„μ›μκΈ° μμ„Έ μΈμ‹
- **μ‹ λΆ°λ„ κΈ°λ° ν•„ν„°λ§**: κ²€μ¶ μ •ν™•λ„μ— λ”°λ¥Έ κ°€μ¤‘μΉ μ μ©

### 4. μ μ‚¬λ„ κ²€μƒ‰ μ•κ³ λ¦¬μ¦ μµμ ν™”

#### μ½”μ‚¬μΈ μ μ‚¬λ„ κ³„μ‚°
```python
def cosine_similarity_search(query_features, db_features):
    # L2 μ •κ·ν™”λ΅ λ‹¨μ„ λ²΅ν„°ν™”
    query_norm = query_features / np.linalg.norm(query_features)
    db_norm = db_features / np.linalg.norm(db_features, axis=1, keepdims=True)
    
    # μ½”μ‚¬μΈ μ μ‚¬λ„ = λ‚΄μ  (μ •κ·ν™”λ λ²΅ν„°λ“¤)
    similarities = np.dot(db_norm, query_norm)
    
    # Top-K μ¶”μ¶
    top_k_indices = np.argsort(similarities)[::-1][:k]
    return top_k_indices, similarities[top_k_indices]
```

#### κ²€μƒ‰ μ„±λ¥ μµμ ν™”
- **νΉμ§• λ²΅ν„° μ‚¬μ „ κ³„μ‚°**: DB μ΄λ―Έμ§€λ“¤μ μ„λ² λ”© λ―Έλ¦¬ μ¶”μ¶ μ €μ¥
- **λ°°μΉ μ²λ¦¬**: μ—¬λ¬ μ΄λ―Έμ§€ λ™μ‹ μ²λ¦¬λ΅ GPU ν™μ©λ„ ν–¥μƒ
- **λ©”λ¨λ¦¬ ν¨μ¨μ„±**: NumPy λ°°μ—΄ κΈ°λ° λ²΅ν„° μ—°μ‚°

### 5. λ°μ΄ν„° νμ΄ν”„λΌμΈ κµ¬μ¶•

#### Stanford Dogs 120 λ°μ΄ν„°μ…‹ ν™μ©
```python
class StanfordDogsDataset(Dataset):
    def __init__(self, root_dir, transform, sample_ratio=1.0):
        self.samples = []
        for breed_dir in os.listdir(root_dir):
            breed_path = os.path.join(root_dir, breed_dir)
            images = os.listdir(breed_path)
            # μƒν”λ§μΌλ΅ ν•™μµ μ‹κ°„ λ‹¨μ¶•
            n_samples = int(len(images) * sample_ratio)
            selected = random.sample(images, n_samples)
            self.samples.extend([os.path.join(breed_path, img) 
                               for img in selected])
```

#### λ°μ΄ν„° μ¦κ°• μ „λµ
- **μ μ ν• μ¦κ°• κ°•λ„**: κ³Όλ„ν• μ¦κ°•μ€ μ¤νλ ¤ μ„±λ¥ μ €ν•
- **κ²¬μΆ…λ³„ νΉμ„± κ³ λ ¤**: μƒ‰μƒ, ν„Έ μ§κ°, ν¬κΈ° λ“± λ³΄μ΅΄
- **Contrastive Learning μµμ ν™”**: Positive pair κ°„ μΌκ΄€μ„± μ μ§€

---

## π“ AI λ¨λΈ μ„±λ¥ λ° μµμ ν™” κ²°κ³Ό

### SimCLR ν•™μµ μ„±κ³Ό
- **ν•™μµ λ°μ΄ν„°**: Stanford Dogs 120 (20,580μ¥ μ¤‘ 50% μƒν”λ§)
- **μµμΆ… Loss**: μ•½ 0.8-1.2 μλ ΄ (40 μ—ν­ κΈ°μ¤€)
- **μ„λ² λ”© μ°¨μ›**: 128-dim (λ©”λ¨λ¦¬ ν¨μ¨μ„±κ³Ό μ„±λ¥ κ· ν•)
- **μ¶”λ΅  μ†λ„**: λ‹¨μΌ μ΄λ―Έμ§€ μ•½ 50ms (GPU κΈ°μ¤€)

### ν‚¤ν¬μΈνΈ κ²€μ¶ μ •ν™•λ„
- **κ²€μ¶ μ„±κ³µλ¥ **: μΌλ°μ μΈ κ°•μ•„μ§€ μ΄λ―Έμ§€ 90% μ΄μƒ
- **μ‹ λΆ°λ„ μ„κ³„κ°’**: 0.3 μ΄μƒ (MMPose κΈ°λ³Έκ°’)
- **μ²λ¦¬ μ‹κ°„**: μ΄λ―Έμ§€λ‹Ή μ•½ 100ms (HRNet-W32 κΈ°μ¤€)

### κ²€μƒ‰ μ‹μ¤ν… μ„±λ¥
- **DB ν¬κΈ°**: μ•½ 10,000μ¥ κΈ°μ¤€
- **κ²€μƒ‰ μ†λ„**: μ‹¤μ‹κ°„ (<1μ΄)
- **λ©”λ¨λ¦¬ μ‚¬μ©λ‰**: μ„λ² λ”© λ²΅ν„° μ•½ 5MB (float32 κΈ°μ¤€)

---

## π€ μµμΆ… AI μ‹μ¤ν… κ²°κ³Όλ¬Ό

### κµ¬ν„λ AI κΈ°λ¥λ“¤
1. β… **SimCLR Contrastive Learning**
   - μκΈ° μ§€λ„ ν•™μµ κΈ°λ° κ°•μ•„μ§€ νΉμ§• μ¶”μ¶
   - 128μ°¨μ› μλ―Έλ΅ μ  μ„λ² λ”© κ³µκ°„ κµ¬μ¶•
   - κ²¬μΆ… λ¶λ³€ νΉμ§• ν•™μµ

2. β… **Vision Transformer ν™μ©**
   - ViT-Tiny λ°±λ³ΈμΌλ΅ λ©”λ¨λ¦¬ ν¨μ¨μ„± ν™•λ³΄
   - Patch-based νΉμ§• μ¶”μ¶
   - Transfer Learning μ μ©

3. β… **MMPose ν‚¤ν¬μΈνΈ κ²€μ¶**
   - 17κ° λ™λ¬Ό ν‚¤ν¬μΈνΈ μ‹¤μ‹κ°„ κ²€μ¶
   - AP-10K λ°μ΄ν„°μ…‹ κΈ°λ° ν•™μµλ λ¨λΈ ν™μ©
   - μ‹ μ²΄ κµ¬μ΅° κΈ°λ° μ μ‚¬λ„ λ¶„μ„

4. β… **μ‹¤μ‹κ°„ μ μ‚¬λ„ κ²€μƒ‰**
   - μ½”μ‚¬μΈ μ μ‚¬λ„ κΈ°λ° λ²΅ν„° κ²€μƒ‰
   - Top-K κ²°κ³Ό λ°ν™ (<1μ΄)
   - νΉμ§• λ²΅ν„° μ‚¬μ „ κ³„μ‚°μΌλ΅ μ†λ„ μµμ ν™”

### μ‚¬μ©λ AI/ML κΈ°μ  μ¤νƒ
- **Deep Learning**: PyTorch, timm, MMPose
- **Computer Vision**: OpenCV, PIL, NumPy
- **Model Architecture**: ViT, HRNet, SimCLR
- **Training**: Contrastive Learning, Mixed Precision
- **Inference**: FastAPI, CUDA acceleration

---

## π’΅ ν•µμ‹¬ AI/ML ν•™μµ ν¬μΈνΈ λ° μΈμ‚¬μ΄νΈ

### 1. Contrastive Learning μ›λ¦¬ μ΄ν•΄
- **Self-Supervised Learning**: λΌλ²¨ μ—†μ΄λ„ μλ―Έμλ” νΉμ§• ν•™μµ κ°€λ¥
- **Positive/Negative Sampling**: κ°™μ€ μ΄λ―Έμ§€μ μ¦κ°•λ³Έμ€ κ°€κΉκ², λ‹¤λ¥Έ μ΄λ―Έμ§€λ” λ©€κ²
- **Temperature Parameter**: ν•™μµ λ‚μ΄λ„ μ΅°μ μ ν•µμ‹¬ ν•μ΄νΌνλΌλ―Έν„°
- **Batch Size ν¨κ³Ό**: λ” λ§μ€ negative sampleμ΄ λ” μΆ‹μ€ μ„±λ¥

### 2. Vision Transformer μ‹¤μ „ ν™μ©
- **Patch Embedding**: CNNκ³Ό λ‹¤λ¥Έ μ΄λ―Έμ§€ μ²λ¦¬ λ°©μ‹μ μ΄ν•΄
- **Attention Mechanism**: κ°•μ•„μ§€ νΉμ§• λ¶€μ„μ— μλ™ μ§‘μ¤‘
- **Model Scaling**: ViT-Tiny vs Base vs Largeμ μ„±λ¥-ν¨μ¨μ„± νΈλ μ΄λ“μ¤ν”„
- **Transfer Learning**: ImageNet μ‚¬μ „ν•™μµμ ν¨κ³Ό

### 3. ν‚¤ν¬μΈνΈ κ²€μ¶ μ „λ¬Έμ„±
- **Domain Adaptation**: μ‚¬λ ν‚¤ν¬μΈνΈμ—μ„ λ™λ¬Ό ν‚¤ν¬μΈνΈλ΅μ ν™•μ¥
- **Multi-Modal Learning**: μ΄λ―Έμ§€ + κµ¬μ΅° μ •λ³΄ κ²°ν•©
- **Confidence Score**: κ²€μ¶ μ‹ λΆ°λ„ κΈ°λ° ν•„ν„°λ§ μ „λµ
- **Real-time Processing**: μ‹¤μ‹κ°„ μ¶”λ΅ μ„ μ„ν• μµμ ν™”

### 4. λ²΅ν„° κ²€μƒ‰ μ‹μ¤ν… μ„¤κ³„
- **Embedding Space**: κ³ μ°¨μ› λ²΅ν„° κ³µκ°„μ—μ„μ μλ―Έλ΅ μ  μ μ‚¬λ„
- **Cosine Similarity**: λ²΅ν„° ν¬κΈ°μ— λ¬΄κ΄€ν• λ°©ν–¥μ„± μ μ‚¬λ„ μΈ΅μ •
- **Indexing Strategy**: λ€μ©λ‰ DBμ—μ„μ ν¨μ¨μ  κ²€μƒ‰ λ°©λ²•
- **Dimensionality**: μ°¨μ› μμ™€ μ„±λ¥-λ©”λ¨λ¦¬ κ· ν•μ 

### 5. λ”¥λ¬λ‹ λ¨λΈ μµμ ν™” λ°©λ²•λ΅ 
- **Mixed Precision Training**: GPU λ©”λ¨λ¦¬ ν¨μ¨μ„± κ·Ήλ€ν™”
- **Gradient Accumulation**: μ‘μ€ λ°°μΉλ΅λ„ ν° λ°°μΉ ν¨κ³Ό
- **Learning Rate Scheduling**: μ•μ •μ  μλ ΄μ„ μ„ν• ν•™μµλ¥  μ΅°μ 
- **Early Stopping**: κ³Όμ ν•© λ°©μ§€ μ „λµ

---

## π”® ν–¥ν›„ AI λ¨λΈ κ°μ„  λ°©ν–¥

### λ”¥λ¬λ‹ λ¨λΈ κ³ λ„ν™”
1. **λ” ν° λ¨λΈ μ‹¤ν—** (ViT-Base, ViT-Large)
2. **Multi-Modal Learning** (μ΄λ―Έμ§€ + λ©”νƒ€λ°μ΄ν„°)
3. **Few-Shot Learning** (μ μ€ μƒν”λ΅ μƒ κ²¬μΆ… ν•™μµ)
4. **Self-Supervised Pre-training** (λ” λ§μ€ unlabeled λ°μ΄ν„° ν™μ©)

### ν‚¤ν¬μΈνΈ μ‹μ¤ν… ν™•μ¥
1. **3D ν‚¤ν¬μΈνΈ κ²€μ¶** (κΉμ΄ μ •λ³΄ ν™μ©)
2. **λ™μ‘ ν¨ν„΄ λ¶„μ„** (λΉ„λ””μ¤ κΈ°λ° ν–‰λ™ μΈμ‹)
3. **κ²¬μΆ…λ³„ νΉν™” λ¨λΈ** (κ²¬μΆ…λ³„ ν‚¤ν¬μΈνΈ νΉμ„± κ³ λ ¤)
4. **μ‹¤μ‹κ°„ ν¬μ¦ μ¶”μ •** (μ›ΉμΊ  κΈ°λ° μ‹¤μ‹κ°„ λ¶„μ„)

### κ²€μƒ‰ μ‹μ¤ν… μµμ ν™”
1. **Approximate Nearest Neighbor** (FAISS, Annoy λ“±)
2. **Multi-Vector Search** (μ—¬λ¬ νΉμ§• λ²΅ν„° μ΅°ν•©)
3. **Semantic Filtering** (κ²¬μΆ…, ν¬κΈ°, μƒ‰μƒ λ“± μ΅°κ±΄ κ²€μƒ‰)
4. **Learning to Rank** (μ‚¬μ©μ ν”Όλ“λ°± κΈ°λ° μμ„ κ°μ„ )

### λ°μ΄ν„° ν™•μ¥ λ° ν’μ§ κ°μ„ 
1. **λ” λ‹¤μ–‘ν• λ°μ΄ν„°μ…‹ ν†µν•©** (Open Images, COCO λ“±)
2. **Data Augmentation κ³ λ„ν™”** (StyleGAN, CycleGAN ν™μ©)
3. **Active Learning** (λ¨λΈμ΄ ν•™μµν•κ³  μ‹¶μ€ λ°μ΄ν„° μλ™ μ„ νƒ)
4. **Cross-Domain Adaptation** (μ‹¤ν—μ‹¤ vs μ‹¤μ  ν™κ²½ λ„λ©”μΈ κ°­ ν•΄κ²°)

---

## π“ κ²°λ΅ 

μ΄ ν”„λ΅μ νΈλ¥Ό ν†µν•΄ **μµμ‹  λ”¥λ¬λ‹ κΈ°μ μ„ ν™μ©ν• μ‹¤μ  AI μ„λΉ„μ¤ κµ¬μ¶•**μ μ „ κ³Όμ •μ„ κ²½ν—ν–μµλ‹λ‹¤. νΉν **SimCLR Contrastive Learning**, **Vision Transformer**, **MMPose ν‚¤ν¬μΈνΈ κ²€μ¶** λ“± μµμ²¨λ‹¨ AI κΈ°μ λ“¤μ„ μ‹¤μ „μ—μ„ μ μ©ν•΄λ³Ό μ μμ—μµλ‹λ‹¤.

κ°€μ¥ ν° μ„±κ³Όλ” **μ΄λ΅ μ  μ§€μ‹μ„ μ‹¤μ  λ™μ‘ν•λ” μ‹μ¤ν…μΌλ΅ κµ¬ν„**ν• κ²ƒμ…λ‹λ‹¤. λ…Όλ¬Έμ—μ„λ§ λ³΄λ SimCLRμ„ μ§μ ‘ κµ¬ν„ν•κ³ , NT-Xent Lossμ μν•™μ  μ›λ¦¬λ¥Ό μ½”λ“λ΅ μ‘μ„±ν•λ©°, Vision Transformerμ λ™μ‘ λ°©μ‹μ„ κΉμ΄ μ΄ν•΄ν•  μ μμ—μµλ‹λ‹¤.

λν• **AI λ¨λΈμ μ „μ²΄ νμ΄ν”„λΌμΈ κµ¬μ¶•**μ„ ν†µν•΄ λ°μ΄ν„° μ „μ²λ¦¬λ¶€ν„° λ¨λΈ ν•™μµ, μ¶”λ΅ , μ„λΉ„μ¤ λ°°ν¬κΉμ§€μ μ „ κ³Όμ •μ„ μ²΄κ³„μ μΌλ΅ ν•™μµν–μµλ‹λ‹¤. νΉν GPU λ©”λ¨λ¦¬ κ΄€λ¦¬, Mixed Precision Training, μ‹¤μ‹κ°„ μ¶”λ΅  μµμ ν™” λ“± μ‹¤μ  ν”„λ΅λ•μ… ν™κ²½μ—μ„ μ¤‘μ”ν• κΈ°μ λ“¤μ„ μµλ“ν–μµλ‹λ‹¤.

ν‚¤ν¬μΈνΈ κ²€μ¶μ„ ν†µν• **Multi-Modal AI μ‹μ¤ν…** κµ¬μ¶• κ²½ν—λ„ λ§¤μ° μ†μ¤‘ν•©λ‹λ‹¤. λ‹¨μν• μ΄λ―Έμ§€ λ¶„λ¥λ¥Ό λ„μ–΄ κµ¬μ΅°μ  μ •λ³΄λ¥Ό ν™μ©ν• κ³ λ„ν™”λ λ¶„μ„ μ‹μ¤ν…μ„ λ§λ“¤ μ μμ—μµλ‹λ‹¤.

μ΄ ν”„λ΅μ νΈλ” **Computer Visionκ³Ό Deep Learningμ μ‹¤μ „ μ μ© λ¥λ ¥**μ„ ν¬κ² ν–¥μƒμ‹μΌ°μΌλ©°, ν–¥ν›„ λ” λ³µμ΅ν• AI μ‹μ¤ν… κ°λ°μ λ“ λ“ ν• κΈ°λ°μ΄ λ  κ²ƒμ…λ‹λ‹¤.

---

*π“… μ‘μ„±μΌ: 2025λ…„ 6μ›” 29μΌ*  
*π‘¨β€π’» κ°λ°μ: μ†μμ •*  
*π¤– κΈ°μ μ¤νƒ: SimCLR, ViT, MMPose, PyTorch, FastAPI*
